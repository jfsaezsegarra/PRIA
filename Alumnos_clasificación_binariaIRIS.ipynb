{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pz696l70mm9G"
      },
      "source": [
        "\n",
        "# Entrena un modelo simple de clasificación binaria utilizando Tensorflow\n",
        "Muestra del conjunto de datos Iris si pertenece a la clase 0 o 1.\n",
        "\n",
        "*  Clase 0: Setosa\n",
        "*  Clase 1: Versicolor\n",
        "\n",
        "[IRIS](https://archive.ics.uci.edu/dataset/53/iris)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1a50qRb-2wRE"
      },
      "source": [
        "TensorFlow ciclo Vida\n",
        "\n",
        "* Preparación de datos\n",
        "* Definición del modelo\n",
        "* Entrenamiento del modelo\n",
        "* Evaluación del modelo en el conjunto de prueba\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmFuhgsZggiw",
        "outputId": "24b13393-709a-463f-e2a7-2a630a64305a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/100, Loss: 0.9517161846160889\n",
            "Epoch 20/100, Loss: 0.8638670444488525\n",
            "Epoch 30/100, Loss: 0.8015820384025574\n",
            "Epoch 40/100, Loss: 0.7618882656097412\n",
            "Epoch 50/100, Loss: 0.7387213110923767\n",
            "Epoch 60/100, Loss: 0.7258583307266235\n",
            "Epoch 70/100, Loss: 0.7180382013320923\n",
            "Epoch 80/100, Loss: 0.7122979760169983\n",
            "Epoch 90/100, Loss: 0.7076823711395264\n",
            "Epoch 100/100, Loss: 0.7040011882781982\n",
            "Accuracy on test set: 0.25\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "\n",
        "X, y = X[:100, :], y[:100]\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Transforma los datos en tensores de TensorFlow\n",
        "X_train_tensor = tf.constant(X_train, dtype=tf.float32)\n",
        "y_train_tensor = tf.constant(y_train, dtype=tf.float32)\n",
        "X_test_tensor = tf.constant(X_test, dtype=tf.float32)\n",
        "\n",
        "\n",
        "class BinaryClassificationModel(tf.Module):\n",
        "    def __init__(self, num_features):\n",
        "        self.W = tf.Variable(tf.random.normal([num_features, 1]), name='weights')\n",
        "        self.b = tf.Variable(tf.zeros([1]), name='bias')\n",
        "\n",
        "    def __call__(self, X):\n",
        "        return tf.sigmoid(tf.matmul(X, self.W) + self.b)\n",
        "\n",
        "\n",
        "num_features = X_train_tensor.shape[1]\n",
        "model = BinaryClassificationModel(num_features)\n",
        "\n",
        "#\n",
        "def binary_cross_entropy_loss(y_true, y_pred):\n",
        "    epsilon = 1e-15\n",
        "    y_pred = tf.clip_by_value(y_pred, epsilon, 1 - epsilon)\n",
        "    return -tf.reduce_mean(y_true * tf.math.log(y_pred) + (1 - y_true) * tf.math.log(1 - y_pred))\n",
        "\n",
        "optimizer = tf.optimizers.Adam(learning_rate=0.01)\n",
        "\n",
        "\n",
        "epochs = 100\n",
        "for epoch in range(epochs):\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(X_train_tensor)\n",
        "        loss = binary_cross_entropy_loss(y_train_tensor, predictions)\n",
        "\n",
        "    gradients = tape.gradient(loss, [model.W, model.b])\n",
        "    optimizer.apply_gradients(zip(gradients, [model.W, model.b]))\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f'Epoch {epoch + 1}/{epochs}, Loss: {loss.numpy()}')\n",
        "\n",
        "\n",
        "# Evalúa el rendimiento del modelo en el conjunto de prueba\n",
        "test_predictions = model(X_test_tensor)\n",
        "rounded_predictions = tf.round(test_predictions)\n",
        "accuracy = accuracy_score(y_test, rounded_predictions.numpy().astype(int))\n",
        "print(f'Accuracy on test set: {accuracy}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnVdXCD5jmtl"
      },
      "source": [
        "Inserta y comprueba los valores insertados de la nueva flor e indica de que tipo es."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5br4Q1GjnDV",
        "outputId": "1def681d-0147-49ba-f1b3-5e044bca256a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "La nueva flor se clasifica como: Clase 1 con una probabilidad de 0.5663756728172302\n"
          ]
        }
      ],
      "source": [
        "# Insertar una nueva flor con los siguientes valores\n",
        "\n",
        "#Longitud del sépalo (en centímetros).5.1\n",
        "#Ancho del sépalo (en centímetros). 3.5\n",
        "#Longitud del pétalo (en centímetros). 1.4\n",
        "#Ancho del pétalo (en centímetros). 0.2\n",
        "\n",
        "#codigo aqui\n",
        "\n",
        "\n",
        "\n",
        "#El codigo se mantien el mismo\n",
        "# Escala la nueva flor utilizando el mismo escalador\n",
        "new_flower_scaled = scaler.transform(new_flower)\n",
        "\n",
        "# Convierte la nueva flor en un tensor de TensorFlow\n",
        "new_flower_tensor = tf.constant(new_flower_scaled, dtype=tf.float32)\n",
        "\n",
        "# Realiza la predicción con el modelo entrenado\n",
        "prediction = model(new_flower_tensor).numpy()[0][0]\n",
        "\n",
        "# Clasifica la flor en función de la predicción\n",
        "predicted_class = 'Clase 1' if prediction >= 0.5 else 'Clase 0'\n",
        "\n",
        "print(f'La nueva flor se clasifica como: {predicted_class} con una probabilidad de {prediction}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztN0c1JKJfNG"
      },
      "source": [
        "1. Explica la salida del código para cada valor\n",
        "\n",
        "\n",
        "*   Epoch\n",
        "*   Loss\n",
        "*   Accuracy\n",
        "\n",
        "\n",
        "\n",
        "2. En que línea del código se realiza la **backpropagation**  \n",
        "*    Explica y comenta\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1JOt8EmKviu"
      },
      "source": [
        "3. Ajusta la tasa de aprendizaje (learning rate) y Aumentar el número de épocas.\n",
        "\n",
        "Explica la salida del código para cada valor\n",
        "\n",
        "\n",
        "*   Epoch\n",
        "*   Loss\n",
        "*   Accuracy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdzG4qlCu0gK"
      },
      "source": [
        "#Capas Ocultas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CstAL_fXdIJf"
      },
      "source": [
        "4. Agrega una capa oculta (hidden_output) con 4 neuronas, utiliza la función de activación ReLU antes de la capa de salida.\n",
        "\n",
        "Explica la salida del código\n",
        "\n",
        "*   Epoch\n",
        "*   Loss\n",
        "*   Accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0eU-6LyIxgv"
      },
      "outputs": [],
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Carga y prepara el conjunto de datos Iris\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Realiza clasificación binaria entre clases 0 y 1\n",
        "X, y = X[:100, :], y[:100]\n",
        "\n",
        "# Escala los datos\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Divide los datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convierte los datos a tensores de TensorFlow\n",
        "X_train_tensor = tf.constant(X_train, dtype=tf.float32)\n",
        "y_train_tensor = tf.constant(y_train, dtype=tf.float32)\n",
        "X_test_tensor = tf.constant(X_test, dtype=tf.float32)\n",
        "\n",
        "class ModifiedModel(tf.Module):\n",
        "    def __init__(self, num_features):\n",
        "\n",
        "'''Crea una variable llamada 'W' que represente los pesos, inicializada con valores aleatorios utilizando una distribución normal, \n",
        "  y una variable 'b' que represente el sesgo, inicializada con ceros.\n",
        "'''\n",
        "\n",
        "\n",
        "    def __call__(self, X):\n",
        "   '''utilizando  la función de activación sigmoide realiza una operación de multiplicación de matrices \n",
        "   entre la matriz de características de entrada 'X' y los pesos del modelo 'W', seguido de la adición del sesgo 'b'.'''\n",
        "\n",
        "        return output\n",
        "\n",
        "# Instancia del modelo\n",
        "num_features = X_train_tensor.shape[1]\n",
        "model = ModifiedModel(num_features)\n",
        "\n",
        "# Función de pérdida y optimizador\n",
        "def binary_cross_entropy_loss(y_true, y_pred):\n",
        "    epsilon = 1e-15\n",
        "    y_pred = tf.clip_by_value(y_pred, epsilon, 1 - epsilon)\n",
        "    return -tf.reduce_mean(y_true * tf.math.log(y_pred) + (1 - y_true) * tf.math.log(1 - y_pred))\n",
        "\n",
        "optimizer = tf.optimizers.Adam(learning_rate=0.01)\n",
        "\n",
        "# Entrenamiento del modelo\n",
        "epochs = 100\n",
        "for epoch in range(epochs):\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(X_train_tensor)\n",
        "        loss = binary_cross_entropy_loss(y_train_tensor, predictions)\n",
        "\n",
        "    gradients = tape.gradient(loss, [model.W_hidden, model.b_hidden, model.W_output, model.b_output])\n",
        "    optimizer.apply_gradients(zip(gradients, [model.W_hidden, model.b_hidden, model.W_output, model.b_output]))\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f'Epoch {epoch + 1}/{epochs}, Loss: {loss.numpy()}')\n",
        "\n",
        "# Evaluación del modelo en el conjunto de prueba\n",
        "test_predictions = model(X_test_tensor)\n",
        "rounded_predictions = tf.round(test_predictions)\n",
        "accuracy = accuracy_score(y_test, rounded_predictions.numpy().astype(int))\n",
        "print(f'Accuracy on test set: {accuracy}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52Ii4d_hdNX1"
      },
      "source": [
        "5.Crea otra  capa adicional con tres neuronas  (self.W_hidden2, self.b_hidden2)  entre la primera capa oculta (self.W_hidden1, self.b_hidden1)   y la capa de salida (self.W_output, self.b_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QDWUql0X9Aa"
      },
      "source": [
        "Entrada (num_features) -> [hidden1 (4 neuronas)] -----> [hidden2 (3 neuronas)  -----> [output (1 neurona)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VkTYJlyNW9aO"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Carga y prepara el conjunto de datos Iris\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Realiza clasificación binaria entre clases 0 y 1\n",
        "X, y = X[:100, :], y[:100]\n",
        "\n",
        "# Escala los datos\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Divide los datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convierte los datos a tensores de TensorFlow\n",
        "X_train_tensor = tf.constant(X_train, dtype=tf.float32)\n",
        "y_train_tensor = tf.constant(y_train, dtype=tf.float32)\n",
        "X_test_tensor = tf.constant(X_test, dtype=tf.float32)\n",
        "\n",
        "# Modelo  capas ocultas y función de activación ReLU\n",
        "class ModifiedModel(tf.Module):\n",
        "    def __init__(self, num_features):\n",
        "        self.W_hidden1 = tf.Variable(tf.random.normal([num_features, 4]), name='hidden1_weights')\n",
        "        self.b_hidden1 = tf.Variable(tf.zeros([4]), name='hidden1_bias')\n",
        "\n",
        "        # (capa oculta adicional con 3 neuronas) codigo aquí\n",
        "    '''\n",
        "    Crea una variable llamada 'W_hidden2', que represente los pesos de la capa oculta, \n",
        "    inicializados con valores aleatorios utilizando una distribución normal, \n",
        "    además de una variable llamada 'b_hidden2', que represente el sesgo de la capa oculta, inicializado con ceros. \n",
        "    \n",
        "    '''\n",
        "    ################## capa de salida\n",
        "    '''\n",
        "    crea una variable llamada 'W_output', que represente los pesos de la capa de salida, \n",
        "    inicializados con valores aleatorios utilizando una distribución normal, \n",
        "    una variable llamada 'b_output', que representa el sesgo de la capa de salida, inicializado con ceros.\n",
        "    '''\n",
        "\n",
        "\n",
        "    def __call__(self, X):\n",
        "        # Operación de la primera capa oculta con ReLU\n",
        "        hidden1_output = tf.nn.relu(tf.matmul(X, self.W_hidden1) + self.b_hidden1)\n",
        "\n",
        "        # Líneas añadidas (operación de la segunda capa oculta con ReLU) añade codigo aquí\n",
        "      '''\n",
        "      utiliza la función de activación ReLU (Rectified Linear Unit) \n",
        "      y que se  realice una operación de multiplicación de matrices entre la salida de la primera capa oculta 'hidden1_output' \n",
        "      y los pesos de la segunda capa oculta 'W_hidden2', seguido de la adición del sesgo 'b_hidden2'\n",
        "      '''\n",
        "\n",
        "        # Operación de la capa de salida con función sigmoide\n",
        "     '''\n",
        "     utiliza la función de activación sigmoide, realiza una operación de multiplicación de matrices entre la salida de la primera capa oculta 'hidden1_output' \n",
        "     y los pesos de la capa de salida 'W_output', seguido de la adición del sesgo 'b_output'\n",
        "          '''\n",
        "\n",
        "        return output\n",
        "\n",
        "# Instancia del modelo\n",
        "num_features = X_train_tensor.shape[1]\n",
        "model = ModifiedModel(num_features)\n",
        "\n",
        "# Función de pérdida y optimizador\n",
        "def binary_cross_entropy_loss(y_true, y_pred):\n",
        "    epsilon = 1e-15\n",
        "    y_pred = tf.clip_by_value(y_pred, epsilon, 1 - epsilon)\n",
        "    return -tf.reduce_mean(y_true * tf.math.log(y_pred) + (1 - y_true) * tf.math.log(1 - y_pred))\n",
        "\n",
        "optimizer = tf.optimizers.Adam(learning_rate=0.01)\n",
        "\n",
        "# Entrenamiento del modelo\n",
        "epochs = 100\n",
        "for epoch in range(epochs):\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(X_train_tensor)\n",
        "        loss = binary_cross_entropy_loss(y_train_tensor, predictions)\n",
        "\n",
        "    gradients = tape.gradient(loss, [model.W_hidden1, model.b_hidden1, model.W_output, model.b_output])\n",
        "    optimizer.apply_gradients(zip(gradients, [model.W_hidden1, model.b_hidden1, model.W_output, model.b_output]))\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f'Epoch {epoch + 1}/{epochs}, Loss: {loss.numpy()}')\n",
        "\n",
        "# Evaluación del modelo en el conjunto de prueba\n",
        "test_predictions = model(X_test_tensor)\n",
        "rounded_predictions = tf.round(test_predictions)\n",
        "accuracy = accuracy_score(y_test, rounded_predictions.numpy().astype(int))\n",
        "print(f'Accuracy on test set: {accuracy}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5tg0NWtkXZ2"
      },
      "source": [
        "5.1 Es mas eficiente el ejercicio 4 o 5 ?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VJRYejkghEk"
      },
      "source": [
        "6.¿Cuál es el propósito de la función binary_cross_entropy_loss?\n",
        "a) Definir la estructura del modelo\n",
        "b) Calcular la precisión del modelo\n",
        "c) Calcular la función de pérdida\n",
        "d) Entrenar el modelo\n",
        "Respuesta correcta: c) Calcular la función de pérdida"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYqNKOqRgjKD"
      },
      "source": [
        "7.¿Qué ocurre en cada iteración del bucle de entrenamiento? Describe brevemente el proceso de entrenamiento del modelo y cómo se actualizan los pesos y sesgos en cada iteración.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vP6CgpNDgvsY"
      },
      "source": [
        "8.¿Cuál es la métrica utilizada para evaluar el rendimiento del modelo en el conjunto de prueba? Explica cómo se calcula esta métrica y su significado en el contexto de la clasificación binaria."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.8 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "195f7d4e7dfa36631d8b035cdcf7a97b6cf52e673cffc7538f8b1ac093d92219"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
